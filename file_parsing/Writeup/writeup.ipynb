{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing Write-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dark web is notoriously difficult to crawl. The Hidden Services directory, which users use to find hidden services, stores hashes of domains to prevent enumeration. Enthusiasts have taken steps to make the dark web more well-known, whether it is through status sites or just posting news regarding the dark web. The process to do so often requires manual enumeration of dark web sites to determine what service they offer and how to access it. Most of the sites availble focus on the markets of the dark web, nor are generally safe if you utilize anti-virus. This project aims to create a dark web crawler to automate the process of finding hidden service URLs on the clear web, and have the results accessible on the clear web. This was done utilizing the Python programming language to parse the Common Crawl Corpus for dark web domains, connect to each domain, and display the results on a Flask app that everyone can access. The efforts outlined in this paper focuse on the big data analysis portion and performing a basic analysis of the top 10 most frequently discovered domains. From the Common Crawl Corpus (for the month of September) 40,239 unique dark web domains were discovered accross 6443 clear web domains. Future work is needed to enable automatic classification of each dark web site."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Public awareness of the dark web has risen the past few years with the take down of the Silkroad market by the FBI and the rise in ransomware attacks. Hidden services, the web sites hosted on the dark web, are not highly connected through hyperlinks like sites on the clearweb, reducing the ability of a user to index the dark web. These services do not use typical Domain Name Service (DNS) resolution; instead a hash of the machine is used in place of the domain name that a user must know to access the service. This hash is typically found either via fellow dark web users or via certain sites on the clear web. \n",
    "A hidden service is often denoted with a .onion top level domain, provided by The Onion Router (TOR) project. To access a service you have to use the TOR browser and have the hash of said hidden service. As previously stated these hashes could be discovered on typical clear web sites such as Reddit or on dark web-oriented sites such as darknetstats.com or deeponionweb.com. It is usually tedious and sometimes unsafe to manually search the clear web for onions, as some of the sites (i.e. darknetstats.com) raise alerts with anti-virus. A safer method would be to use open-sourced data to search for hidden services and try to rank clear web sites by the amount of unique dark web domains found on each one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Technologies\n",
    "To begin, we first sought to find a safe method to gather data on the clear web, without having to crawl it ourselves. The Common Crawl organization each month runs a crawler to index the clear web. The organization then saves their findings to compressed warc.wet files. Each file contains multiple indexed websites along with the content that is hosted on them. The warc.wet files were optimal as they were not only smaller than the .wet files, but they also provided only the plaintext extracted from the source code, which removed the concern that the script will have to filter out HTML code which would increase the speed and size of the script. These files have the specified format outlined in Figure 1.\n",
    "![](Final_Images/cc_format.png)\n",
    "*__Figure 1__: Common Crawl file format*\n",
    "\n",
    "\n",
    "The Common Crawl corpus is hosted via Amazon Web Services (AWS), thus we had to download the scripts utilizing wget. The corpus we used was from September of 2019, keep in mind the goals of this project was being developed in late 2019, but waited until the start of the second semester to begin in full swing. All of the common crawl files were saved to a Linux cluster owned by Major (MAJ) Daniel Hawthorne. For this project, the cluster allocated 8 GB RAM, 10 TB of storage, and 8 threads. All of the files summed up to 8.9 TB in total, leaving 1.1 TB left for anything we need. The programming language that we decided to use was Python. This was due to the extensive library it provided and that it was the only programming language I was comfortable with. The last piece of technology that was utilized was Aquamentus. Aquamentus is Linux computer system that features: 14 TB Solid State Drive (SSD), 128 GB RAM, and 32 threads. This is another system built and owned by MAJ Hawthorne that run the final scripts against the common crawl files. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methodology\n",
    "The methodology to process the data first begins with the Common Crawl. The Common Crawl crawls the web each month and saves the results to a GZipped Warc-Wet file. The python script will query the common crawl for the monthly data and save it to the local machine. Once all of he files are saved, the script will open the number of processors relative to  the available RAM on the machine. The script will determine how many files need to be parsed, and allocate an even amount to each processor. Next it will open the file and search for dark web sites utilizing a regular expression. Once a dark web site is found the site along with the clear web site it was found on are written to a CSV. The CSV has the name of the corresponding file that is open to help track sites. Once the script is finished parsing each file, another script starts up where it combines all the CSVs into one dump file. The script will then count the unique dark web and clear web sites and output them to two separate CSVs for analysis. The following will be described in the next few paragraphs: development of the regular expression, onion finder script, and the counter script."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular Expression Development\n",
    "1. (?:https?\\:\\/\\/)?[a-zA-Z2-7]{16}\\.onion?(?:\\/([^/]*))?$ (Intitial)\n",
    "2. (?:https?\\:\\/\\/)?[a-zA-Z2-7]{16}\\.onion?(?:\\/([^/\\s]*))? (Accounts for whitepsace)\n",
    "3. [a-zA-Z2-7]{16}\\.onion?(?:\\/([^/ \\s]*))? (No longer searches for www, htttp, https)\n",
    "4. [a-zA-Z2-7]{16}\\.onion?(?:\\/([^/ \\\\\\s]*))? (Attempt to remove \\r \\n \\t characters)\n",
    "    a. Started to compile regex once to improve performance\n",
    "5. [a-zA-Z2-7]{16}|[a-zA-Z2-7]{56})\\.onion?(?:\\/([^/ \\\\\\s]*))? (Searches for v2 and v3 onions) (FINAL: NO LONGER SUCKS!! :))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Onion Finder Development\n",
    "The onion finder script focused on parsing each common crawl file for darkweb domains and recording the clearweb site it was discovered on. The first task that needed to be accomplished was development of the regular expression (regex). The regular expression had to match strings with the specifications of a valid onion domain. According to specifications from the TOR project, a valid onion is 16 characters in length that is comprised of any letter and number from 2 until 7. Since we wanted to extract the complete onion address the initial regular expression was: \n",
    "\n",
    "(?:https?://)?[a-zA-Z2-7]{16}.onion?(?:/([^/]*))?$\n",
    "\n",
    "To validate that this expression worked, it was inputted into the online regex tester at https://regex101.com along with randomly generated valid and invaid onion domains that meet the specifications. The result from this test showed that the regex would find the onion domain and take everything that occurred after the domain, including spaces. This would skew results as it would return the rest of the file once it found a domain in the common crawl. To remediate the error, the regex was updated to account for whitespace:\n",
    "\n",
    "(?:https?://)?[a-zA-Z2-7]{16}.onion?(?:/([^/\\s]*))?\n",
    "\n",
    "The patch was verified with the online regex tester, however running the regex on a local file, the regex extracted various string literals such as tab and return characters. We also determined that it was unecessary to check for the protocol (HTTP/HTTPS) or www in the URL for the following reasons: 1/TOR only uses HTTPS by default so checking for the protocol is pointless. 2/ onions cannot be accessed from the clear web, so www will only generate errors when connecting to the service. With these two new determinations, the regex was shortened to:\n",
    "\n",
    "[a-zA-Z2-7]{16}.onion?(?:/([^/ \\\\s]*))?\n",
    "\n",
    "The final regex came after the discovery that TOR plans to start implementing what it called v3 onions. v3 onions use a longer hash length of 56 to not only improve security but to expand the space available on the dark web. We originally only checked for v2 onions that were 16 characters long. As such we once again updated the regex to its final form:\n",
    "\n",
    "[a-zA-Z2-7]{16}|[a-zA-Z2-7]{56}).onion?(?:/([^/ \\\\s]*))?\n",
    "\n",
    "the next step was to develop the script itself. Initial success was with the warc3-wet library written by William Zhang. This library while simple to use was not efficient in terms of speed. For the seven test files utilized on a local machine, it took the script 189 seconds to complete. This did not seem too bad, however once the calculations were done to estimate the time it would take to parse through 55985 files, it would have taken approximately 17.5 days for the script to run. Since this was the initial test phase, this was run on the cluster hosted by MAJ Hawthorne where it did in fact take 2.5 weeks. From that run, 5400 unique dark web domains were discovered accross 5689 clear web sites. After this, the common crawl files were transferred over to Aquamentus for further testing. To verify the accuracy of the script, Mr. King ran a Ruby script which utlized the Java file stream library. With his script, he found 39,838 unique dark web sites over 6,393 clear web domains. Confused as to why his script found substantially more than mine did. After reviewing the code I believe the culprit to be the re.search method. Attempts were made to modify the script to use re.findall, however for some reason failed to capture the full string. A quick review of Python's documentation lead to my discovery that re.search returns only the first instance, so it was not even completely parsing each file. To remidiate this, I ended up creating a separate function that generates dark web domains with the regular expression, instead of just calling it on the content itself.\n",
    "\n",
    "Running the script again on my local files, it did find substantially more dark web sites but still took unecessarily long to do so. A review of the warc library showed that it was written with an emphasis on ease of use and not speed. Searching Google, I learned that Common Crawl files could be read usnig the gzip and io libraries, both of which are native to python. These libraries fed provided data line-by-line, which eliminated the need for the generator function. Re-writing the script this way decreased the time it took to parse the 7 files from 189 seconds down to 98 seconds. At 16 processors, this equated to approximately 9 days. See Figure 2 for the speed test results. At this time, we were ready to run the script on Aquamentus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3deZgdZZn+8e/NLsgqIRMIw2ZANgWJgICKogIKggsSBCcoioyMLCOj4OigXmYGR0UcFTEqkmGPC4LgQsQBBBVI2CSE/IgESSCQALJrgHD//qi3DyfNOd3VSU6fTvr+XFdfp+qtqreeqq5znqq3NtkmIiICYKVuBxAREUNHkkJERDQkKUREREOSQkRENCQpREREQ5JCREQ0JCnEgEi6WtJHuh1HfySNkDRT0hpLOP0/S3pI0lOSXlE+tyzDzpH0pWUbce24filpfB/DuxZbb5L2ljS3i/Pvd1uVtLqkuyRtNFhxDXVJCssJSXtJ+r2kxyU9Kul6Sa/rdlw9JJ1VfjifkvSspOea+n+5BPUdKem6pQjpZOCHtv9e6pveFM9Tkp6X9PM2814VOB14u+2X236kfN6zFPEsE7b3tz0Jlsk6QtLEkjxfkHRki+FbSrpc0pOSHpb0333UZUmvXJp4BpvthcDZwKe7HctQkaSwHJC0DnA58E1gA2AT4AvAwm7G1cz2MeWH8+XAfwIX9/Tb3n8wY5G0OjAeOK8pvu2b4lsbuA/4UZsqRgJrANM7HesQcBvwceDm3gMkrQZMAX4L/AMwmqZ1uqxJWrlTdffjAmB82W6GvSSF5cPWALYvtL3I9t9sX2n7dmjsMV4v6ZvlSOIuSfv0TCxpXUk/kDRP0v2SvtT8BZT0YUkzJP1V0q8lbdY07G2lvsclfQvQQIOXtHs5ynlM0m2S9m4adqSke8qe6GxJh0vaFjgLeH3Zq3+sjPsOSXeWce+XdFKbWe4GPGa7XdPFG4GNgJ+0iHVrYGbpfUzSb0t5271gSQdIurUs3+8lvbpp2KdLrE+WPfJ9Wky/RZl2pdL/fUnzm4afJ+mE0n21pI+0W0fF+pKuKPO8QdJWbdYDtr9t+yrg7y0GHwk8YPt020/b/nvPNtdiGa4tnbeVeA5tGvZJSfPL9vehpvJzJH1H0i8kPQ28WdLGkn4iaUHZHo5rGn9XSX8o62qepG+VxNUzvO22KumVkq4pwx6WdHHTOpgL/BXYvd16GlZs52+I/wHrAI8Ak4D9gfV7DT8SeB44EVgVOBR4HNigDP8Z8F1gLaofwxuBj5VhBwOzgG2BVYDPAr8vwzYEngDeV+o9scznI/3E+3ngvNK9SYn9HVQ7IW8r/SNKPE8A25RxRwHbNy3Tdb3qnQe8oXSvD7y2zfyPBa7oI76zgXP6GL45YGCVpjIDryzd5wBfKt2vBeZTJaKVqY5Q7gVWB7YB5gAbN9W7VZt53gfsUrpnAvcA2zYN27l0X92z/tuso3OAR4Fdy//zfOCiGtvYdcCRLdbTucAvgYfLvHfso47GOir9e5ft5Ytl+3kH8Axl+y2xPg7sWbaNNYFpwH8AqwFblvWwbxl/F6of7lXKupwBnFBnWwUuBP69zGcNYK9esV8GHNft7/pQ+MuRwnLA9hPAXlRfuu8BCyRdJmlk02jzgTNsP2f7YqoflneWcfan+vI8bXs+8HVgXJnuY8B/2Z5h+3mqpp+dytHCO4A7bf/Y9nPAGcCDAwz/COAXtn9h+wXbU4CppW6AF4AdJL3M9jzbfTXZPAdsJ2kd23+1/ZImj2I94MlWAyStSfXDcc4Al6OdjwLftX2Dq6O4SVTNersDi6iSw3aSVrV9r+0/t6nnGuBNkv6h9P+49G9BtVNw2wBi+qntG8v/83xgpyVYLqiai8YB/wNsDFwBXNq8d17Dc8AXy3b5C+ApqmTZ41Lb19t+AdgRGGH7i7afdXUO53slBmxPs/1H28/bvpdqR+dNpZ7+ttXngM2oEvTfbfc+F/Mk1XYz7CUpLCfKj/aRtkcDO1B9Sc9oGuV+l12e4i9lnM2o9pzmlcPux6i+TD1XW2wGfKNp2KNUh92blOnnNMXg5v6aNgMO6am/zGMvYJTtp6mOao4p8V0h6VV91PVeqi//X0pTwOvbjPdXqvMGrbyHahmvGeBytLMZ8Mley7cp1Y/PLOAEqiOn+ZIukrRxm3quodqzfiNwLdVe+ZvK3+/Kj2ZdzT+GzwAvH8C0zf5GdSTyS9vPAl8FXkF1VFnXIyU5tYuneXvaDNi417r8DNU5HiRtreqk94OSnqDagdmwTNvftvopqu36RlUXHXy4V5xrA48RSQrLI9t3Ue3p7tBUvImk5vb+fwQeoPpiLAQ2tL1e+VvH9vZlvDlUTUnrNf29zPbvqZprNu2psNS/KQMzBzi3V/1r2T6tLMuvbb+NqunoLqo9Q6iOinov9022D6JKaD8DJreZ5+2U8zAtjAf+t1cCXRpzgAm9lm9N2xeWmC+wvRfVD56BL7ep5xrgDVSJ4Rqq5pw9qZJCuwTW6Ucc3z4I82iufw4wu9e6XNt2z1Hld6i2kTG216FKGD3bfJ/bqu0HbX/U9sZUR8dn9jpHtC0DOxpbYSUpLAckvaqcrBtd+jcFDgP+2DTaRsBxklaVdAjVRv4L2/OAK4GvSVpH0kqStpLUc9h9FnCKpO1L3euW6aFqLthe0nskrQIcR3UVykCcBxwoaV9JK0taQ9X166MljZT0LklrUSWup6iaXAAeAkb3NFVIWk3VSeh1S/PAE03j9nYjsJ6kTXqtx9HAm6nOzSwr3wOOkbSbKmtJeqektSVtI+ktqq5q+TvVnnfLmG3fXYYfAVxbmgwfojo6apcUFltHS6Ks1zWoflxXLf+fnt+F84DdJb1V1YUJJ1CdW5jRRzxbLmksVP+3J1SdnH9Z2V520IuXXq9N9X9/qhxR/nPTtH1uq5IO6fn+UB1JmvK/KNvJBiz+fRq2khSWD09Snci8oVyl8UfgDuCTTePcAIyh+tJOAN5n+5Ey7J+oTtzdSfWF+DHVnjm2L6Hae72oHJLfQXUOAtsPA4cAp1GdHB4DXD+QwG3PAQ6i2qtbQLU3+G9U295KZRkeoGrSeRPV5ZFQXQY5HXhQ0sOl7IPAvSXOY6h+QFvN81mqI6newz8I/KGPdv0Bsz2V6rzCt6jW7SyqE8BQnU84jep/8iBV4v5MH9VdQ9Xccl9Tv4Bb2ozfah0N1JVUyWgPYGLpfiOA7ZlU6/AsqmU7CHhXWb+tfB6YVJp+3j/QQGwvAg6kOgcym2q9fR9Yt4xyEvABqu/D94DmK4j621ZfR/X9eYrqpPLxtmeXYR8AJrm6Z2HY07I7io5uUXXT0UdKM0VQ3dEM/I7qqp2/dTueGJrKUdxtwBvLRRjD3irdDiCiE2wvAPo6aR1BOTrIdtIkzUcREdGQ5qOIiGjIkUJERDQs1+cUNtxwQ2+++ebdDiMiYrkybdq0h22PaDVsuU4Km2++OVOnTu12GBERyxVJf2k3LM1HERHRkKQQERENSQoREdGQpBAREQ1JChER0ZCkEBERDUkKERHRkKQQERENSQoREdGwXN/RvNQWe3vlMJSHIUZELzlSiIiIhiSFiIhoSFKIiIiGJIWIiGhIUoiIiIYkhYiIaEhSiIiIhiSFiIhoSFKIiIiGjiUFSdtIurXp7wlJJ0jaQNIUSXeXz/WbpjlF0ixJMyXt26nYIiKitY4lBdszbe9keydgF+AZ4BLgZOAq22OAq0o/krYDxgHbA/sBZ0pauVPxRUTESw1W89E+wJ9t/wU4CJhUyicBB5fug4CLbC+0PRuYBew6SPFFRASDlxTGAReW7pG25wGUz41K+SbAnKZp5payxUg6WtJUSVMXLFjQwZAjIoafjicFSasB7wJ+1N+oLcpe8hhP2xNtj7U9dsSIEcsixIiIKAbjSGF/4GbbD5X+hySNAiif80v5XGDTpulGAw8MQnwREVEMRlI4jBebjgAuA8aX7vHApU3l4yStLmkLYAxw4yDEFxERRUdfsiNpTeBtwMeaik8DJks6CrgPOATA9nRJk4E7geeBY20v6mR8ERGxuI4mBdvPAK/oVfYI1dVIrcafAEzoZEwREdFe7miOiIiGJIWIiGhIUoiIiIYkhYiIaEhSiIiIhiSFiIhoSFKIiIiGJIWIiGhIUoiIiIYkhYiIaEhSiIiIhiSFiIhoSFKIiIiGJIWIiGhIUoiIiIYkhYiIaEhSiIiIhiSFiIhoSFKIiIiGfpOCpK0krV6695Z0nKT16lQuaT1JP5Z0l6QZkl4vaQNJUyTdXT7Xbxr/FEmzJM2UtO+SL1ZERCyJOkcKPwEWSXol8ANgC+CCmvV/A/iV7VcBrwFmACcDV9keA1xV+pG0HTAO2B7YDzhT0soDWJaIiFhKdZLCC7afB94NnGH7RGBUfxNJWgd4I1Uiwfazth8DDgImldEmAQeX7oOAi2wvtD0bmAXsOpCFiYiIpVMnKTwn6TBgPHB5KVu1xnRbAguAH0q6RdL3Ja0FjLQ9D6B8blTG3wSY0zT93FK2GElHS5oqaeqCBQtqhBEREXXVSQofAl4PTLA9W9IWwHk1plsFeC3wHds7A09TmoraUIsyv6TAnmh7rO2xI0aMqBFGRETU1W9SsH2n7eNsX1j6Z9s+rUbdc4G5tm8o/T+mShIPSRoFUD7nN42/adP0o4EH6i1GREQsC6u0GyDpT7TYU+9h+9V9VWz7QUlzJG1jeyawD3Bn+RsPnFY+Ly2TXAZcIOl0YGNgDHDjAJYlIiKWUtukABxQPo8tn+eWz8OBZ2rW/wngfEmrAfdQNUWtBEyWdBRwH3AIgO3pkiZTJY3ngWNtL6q7IBERsfRktz0YqEaQrre9Z39l3TB27FhPnTp1yStQq9MYw0g///uIWDFJmmZ7bKthdU40ryVpr6bK9gDWWlbBRUTE0NFX81GPo4CzJa1b+h8DPty5kCIiolv6TQq2pwGvKTejyfbjnQ8rIiK6od+kUJ579F5gc2AVlXZ421/saGQRETHo6jQfXQo8DkwDFnY2nIiI6KY6SWG07f06HklERHRdnauPfi9px45HEhERXVfnSGEv4EhJs6majwS4vzuaIyJi+VMnKezf8SgiImJIqPNAvL8A6wEHlr/1SllERKxg6ryO83jgfKr3HmwEnCfpE50OLCIiBl/dO5p3s/00gKQvA38AvtnJwCIiYvDVufpIQPPTShfR+oU4ERGxnKtzpPBD4AZJl5T+gynvXY6IiBVLnWcfnS7paqpLUwV8yPYtnQ4sIiIGX51nH+0OTLd9c+lfW9JuTa/ZjIiIFUSdcwrfAZ5q6n+6lEVExAqm1olmN72ezfYL1DsXERERy5k6SeEeScdJWrX8HU/1vuV+SbpX0p8k3SppainbQNIUSXeXz/Wbxj9F0ixJMyXtu2SLFBERS6pOUjgG2AO4H5gL7AYcPYB5vNn2Tk3vAz0ZuMr2GOCq0o+k7YBxwPbAfsCZklYewHwiImIp1bn6aD7Vj/WychCwd+meBFwNfLqUX2R7ITBb0ixgV6ob5SIiYhDUeczF1pKuknRH6X+1pM/WrN/AlZKmSeo5uhhpex5A+dyolG8CzGmadm4pi4iIQVKn+eh7wCnAcwC2b6f+kcOetl9L9aTVYyW9sY9xW90l7ZeMJB0taaqkqQsWLKgZRkRE1FEnKaxp+8ZeZc/Xqdz2A+VzPnAJVXPQQ5JGAZTP+WX0ucCmTZOPBh5oUedE22Ntjx0xYkSdMCIioqY6SeFhSVtR9tolvQ+Y199EktaStHZPN/B24A7gMmB8GW081TugKeXjJK0uaQtgDNA7GUVERAfVud/gWGAi8CpJ9wOzgcNrTDcSuERSz3wusP0rSTcBkyUdBdwHHAJge7qkycCdVEcix9pe1LrqiIjoBDXdl9b3iNXe/kq2n+xsSPWNHTvWU6dOXfIKNMwf9lrzfx8RKxZJ05puE1hM2+YjSQdK2qyp6JPAdZIuK807ERGxgunrnMIEYAGApAOAI4APU7X9n9X50CIiYrD1lRRs+5nS/R7gB7an2f4+kMt+IiJWQH0lBUl6uaSVgH2oHknRY43OhhUREd3Q19VHZwC3Ak8AM2z3PNBuZ2pckhoREcuftknB9tmSfk31GIrbmgY9CHyo04FFRMTg6/M+Bdv3Uz0dtbksRwkRESuoOnc0R0TEMJGkEBERDbVeq1ledjOyeXzb93UqqIiI6I5+k4KkTwCnAg8BL5RiA6/uYFwREdEFdY4Ujge2sf1Ip4OJiIjuqnNOYQ7weKcDiYiI7qtzpHAPcLWkK4CFPYW2T+9YVBER0RV1ksJ95W+18hcRESuofpOC7S8MRiAREdF9bZOCpDNsnyDp55RXcTaz/a6ORhYREYOuryOFc8vnVwcjkIiI6L6+Hog3rXxeM3jhREREN3X8MReSVpZ0i6TLS/8GkqZIurt8rt807imSZkmaKWnfTscWERGLG4xnHx0PzGjqPxm4yvYYqhf3nAwgaTtgHLA9sB9wZnm8RkREDJLaSUHSWgOtXNJo4J3A95uKDwImle5JwMFN5RfZXmh7NjAL2HWg84yIiCXXb1KQtIekOyl7+5JeI+nMmvWfAXyKF5+ZBDCy550M5XOjUr4J1d3TPeaWst7xHC1pqqSpCxYsqBlGRETUUefmta8D+wKXAdi+TdIb+5tI0gHAfNvTJO1dYz5qUdbqUtiJwESAsWPHvmR4DKILWv3LhpEPZPOLFU+tR2fbniMt9gOwqMZkewLvkvQOYA1gHUnnAQ9JGmV7nqRRwPwy/lxg06bpRwMP1IkvIiKWjVoPxJO0B2BJq0k6icVPHLdk+xTbo21vTnUC+be2j6A64hhfRhsPXFq6LwPGSVpd0hbAGODGgS1OREQsjTpHCscA36Bq358LXAkcuxTzPA2YLOkoqmcqHQJge7qkycCdwPPAsbbrHJFERMQyUufZRw8Dhy/NTGxfDVxduh8B9mkz3gRgwtLMKyIillydN69tAXwC2JzFX8eZZx9FRKxg6jQf/Qz4AfBzFr+0NCIiVjB1ksLfbf9PxyOJiIiuq5MUviHpVKoTzM1vXru5Y1FFRERX1EkKOwIfBN7Ci81HLv0REbECqZMU3g1safvZTgcTERHdVefmtduA9TodSEREdF+dI4WRwF2SbmLxcwq5JDUiYgVTJymc2vEoIiJiSKhzR3NexxkRMUy0TQqSrrO9l6QnWfwR1gJse52ORxcREYOqbVKwvVf5XHvwwomIiG6q8+a1c+uURUTE8q/OJanbN/dIWgXYpTPhREREN7VNCpJOKecTXi3pifL3JPAQL74YJyIiViBtk4Lt/yrnE75ie53yt7btV9g+ZRBjjIiIQdJv81ESQETE8FHnnEJERAwTSQoREdFQKylI2kvSh0r3iPKKzv6mWUPSjZJukzRd0hdK+QaSpki6u3yu3zTNKZJmSZopad8lXaiIiFgyde5TOBX4NNBzbmFV4LwadS8E3mL7NcBOwH6SdgdOBq6yPQa4qvQjaTtgHNUlsPsBZ0paeWCLExERS6POkcK7gXcBTwPYfgDo9y5nV54qvauWPwMHAZNK+STg4NJ9EHCR7YW2ZwOzgF1rLkdERCwDdZLCs7ZNef6RpLXqVi5pZUm3AvOBKbZvAEbangdQPjcqo28CzGmafG4p613n0ZKmSpq6YMGCuqFEREQNdZLCZEnfBdaT9FHgN8D36lRue5HtnYDRwK6SduhjdLWqokWdE22PtT12xIgRdcKIiIia6jw6+6uS3gY8AWwD/IftKQOZie3HJF1Nda7gIUmjbM+TNIrqKAKqI4NNmyYbDTwwkPlERMTSqXX1ke0ptv/N9kl1E0K5Smm90v0y4K3AXcBlwPgy2nhefGTGZcA4SauXq5vGADfWX5SIiFha/R4ptHifAsDjwFTgk7bvaTPpKGBSuYJoJWCy7csl/YGqSeoo4D7gEADb0yVNBu4EngeOtb1oSRYqIiKWTJ3XcZ5O1YxzAVW7/zjgH4CZwNnA3q0msn07sHOL8keAfdpMMwGYUCOmiIjogDrNR/vZ/q7tJ20/YXsi8A7bFwPr9zdxREQsP+okhRckvV/SSuXv/U3DXnJ1UERELL/qJIXDgQ9SXSX0UOk+opw8/pcOxhYREYOsziWp9wAHthl83bINJyIiuqnO1UdrAEdRPZNojZ5y2x/uYFwREdEFdZqPzqW62mhf4Bqqm8qe7GRQERHRHXWSwittfw542vYk4J3Ajp0NKyIiuqFOUniufD5Wnl20LrB5xyKKiIiuqXPz2sTyIpzPUj2K4uXA5zoaVUREdEWfSUHSSsATtv8KXAtsOShRRUREV/TZfGT7BXIvQkTEsFHnnMIUSSdJ2rS8X3kDSRt0PLKIiBh0dc4p9NyPcGxTmUlTUkTECqfOHc1bDEYgERHRff02H0laU9JnJU0s/WMkHdD50CIiYrDVOafwQ+BZYI/SPxf4UsciioiIrqmTFLay/d+Um9hs/43qZTsREbGCqZMUni2PyTaApK2AhR2NKiIiuqJOUvg88CtgU0nnA1cBn+pvonIJ6/9JmiFpuqTjS/kGkqZIurt8rt80zSmSZkmaKWnfJVukiIhYUnWuPrpS0jRgd6pmo+NtP1yj7ueBT9q+WdLawDRJU4AjgatsnybpZOBk4NOStqN6//P2wMbAbyRtbXvREi1ZREQMWJ2rjy4D3g5cbfvymgkB2/Ns31y6nwRmAJsABwGTymiTgINL90HARbYX2p4NzAJ2HcjCRETE0qnTfPQ14A3AnZJ+JOl95cU7tUnaHNgZuAEYaXseVIkD2KiMtgkwp2myuaUsIiIGSb9JwfY1tj9OdQfzROD9VO9rrkXSy4GfACfYfqKvUVvNvkV9R0uaKmnqggUL6oYRERE11DlSoFx99F7gGOB1vNj80990q1IlhPNt/7QUPyRpVBk+ihcTzFxg06bJRwMP9K7T9kTbY22PHTFiRJ0wIiKipjrnFC6mOh/wFuDbVPctfKLGdAJ+AMywfXrToMuA8aV7PHBpU/k4SatL2gIYA9xYd0EiImLp1Xkg3g+BD/RcBSRpT0kfsH1sP9PtCXwQ+JOkW0vZZ4DTgMmSjgLuAw4BsD1d0mTgTqorl47NlUexItMXhvc9oD71Ja3DMQTUuST1V5J2knQYcCgwG/hpP5Nh+zra3/m8T5tpJgAT+qs7IiI6o21SkLQ11X0DhwGPABcDsv3mQYotIiIGWV9HCncBvwMOtD0LQNKJgxJVRER0RV8nmt8LPAj8n6TvSdqHPAgvImKF1jYp2L7E9qHAq4CrgROBkZK+I+ntgxRfREQMojo3rz1t+3zbB1DdO3Ar1fOKIiJiBVPr5rUeth+1/V3bb+lUQBER0T0DSgoREbFiS1KIiIiGJIWIiGhIUoiIiIYkhYiIaEhSiIiIhiSFiIhoSFKIiIiGJIWIiGhIUoiIiIYkhYiIaEhSiIiIhiSFiIho6FhSkHS2pPmS7mgq20DSFEl3l8/1m4adImmWpJmS9u1UXBER0V4njxTOAfbrVXYycJXtMcBVpR9J21G9D3r7Ms2ZklbuYGwREdFCx5KC7WuBR3sVHwRMKt2TgIObyi+yvdD2bGAWsGunYouIiNYG+5zCSNvzAMrnRqV8E2BO03hzS9lLSDpa0lRJUxcsWNDRYCMihptVuh1AoRZlbjWi7YnARICxY8e2HCciVnxq9asxjLhDv36DfaTwkKRRAOVzfimfC2zaNN5o4IFBji0iYtgb7KRwGTC+dI8HLm0qHydpdUlbAGOAGwc5toiIYa9jzUeSLgT2BjaUNBc4FTgNmCzpKOA+4BAA29MlTQbuBJ4HjrW9qFOxRUREax1LCrYPazNonzbjTwAmdCqeiIjoX+5ojoiIhiSFiIhoSFKIiIiGJIWIiGhIUoiIiIYkhYiIaEhSiIiIhiSFiIhoSFKIiIiGJIWIiGhIUoiIiIYkhYiIaEhSiIiIhiSFiIhoSFKIiIiGJIWIiGhIUoiIiIYkhYiIaEhSiIiIhiGXFCTtJ2mmpFmSTu52PBERw8mQSgqSVga+DewPbAccJmm77kYVETF8DKmkAOwKzLJ9j+1ngYuAg7ocU0TEsLFKtwPoZRNgTlP/XGC35hEkHQ0cXXqfkjRzkGLrhA2Bh7s2d6lrs15Gurv+Ds/6Wxr6fNbf0ljKr+9m7QYMtaTQajG9WI89EZg4OOF0lqSptsd2O47lVdbf0sn6Wzor6vobas1Hc4FNm/pHAw90KZaIiGFnqCWFm4AxkraQtBowDrisyzFFRAwbQ6r5yPbzkv4F+DWwMnC27eldDquTVohmsC7K+ls6WX9LZ4Vcf7Ld/1gRETEsDLXmo4iI6KIkhYiIaBhWSUHS1yWd0NT/a0nfb+r/mqR/Ld2rSHpY0n/1quPq8hiO2yTdJGmnpmH7S5oqaYakuyR9tU0cB0v6j9L9eUnPSNqoafhTA1yueyX9rlfZrZLuKN17S3pc0i0ltlNL+Y6Szqk5D0v6WlP/SZI+3880e0vao6n/GEn/VH/J+qz7hJ66JJ0j6X5Jq5f+DSXdO8D6LOncpv5VJC2QdHnpP7L03yrpTkkfLeUHSPrCslimJVF3m+7k9rw8G2rb9VAwrJIC8HtgDwBJK1HdfLJ90/A9gOtL99uBmcD7pZfcJnK47dcAZwJfKfXtAHwLOML2tsAOwD1t4vhUmbbHw8Anl3CZeqwtadMSy7Ythv/O9s7AWOAISbvY/hMwWtI/1qh/IfAeSRsOIKa9KesbwPZZtv93ANO3JGkV4MPABU3Fi0rZknoa2EHSy0r/24D7e41zse2dqJbrPyWNBK4A3iVpzaWY99Kou013cnteng2Z7XqoGG5J4Xpe/GduD9wBPClp/bKXuS1wSxl+GPAN4D5g9zb1/YHqLmyofugn2L4LqiupbJ/ZewJJWwMLbTffCXk2cKikDVqM/6+S7ih/J/Qe3mQycGhT7Be2Gsn208A0YKtS9HOqS3/78zzV1RYntojxQEk3lCOR30gaKWlz4BjgxLJ3/YZyVHSSpG0l3dg0/eaSbi/du0i6RtK0stc7qkUsbwFutv18U9kZZV6LXVGnylfK+vuTpENp72WGhZ0AAAY+SURBVJfAO0t3X+twPvBnYDNXV2pcDRzQR72dVHeb7sj2vAIYStv1kDCskoLtB4Dny57xHlRfghuA11PtQd9u+9myt7gPcDnVD8NhbarcD/hZ6d6B6se2P3sCN/cqe4oqMRzfXChpF+BDVI/62B34qKSd29T7Y+A9pftAqh/7l5D0ilJXz6W+U4E31IgbqocVHi5p3V7l1wG7lyORi4BP2b4XOAv4uu2dbDeat2zPAFaTtGUpOhSYLGlV4JvA+2zvQrVOJrSIY09euq7vK3F8sFf5e4CdgNcAbwW+0scX8iJgnKQ1gFdTbRsvUeLeEphVigayDpepOts01eXdndqeVwRDZbseEobUfQqDpGfPag/gdKo9oz2Ax6kOxaHa6/s/289I+gnwOUkn2l5Uhp8vaS2qL9trBzj/UcCCFuX/A9za3L4J7AVcUvbukfRTqh+fW1pM/yjwV0njgBnAM72Gv0HSLcALwGlN93/MBzauE7jtJyT9L3Ac8LemQaOBi8uP7WrA7BrVTQbeD5xG9eU5FNiG6sdoSmnhWBmY12LaUVTL2Nt/Ut3seEVT2V7AheV/95Cka4DX0eKmSNu3lz3Bw4BftKj/UEl7UTU5fMz2o6W89jrskP626U5uz8u9IbRdDwnD6kih6GmD3ZHqUPuPVHtVzecTDgPequpk5TTgFcCbm+o4HNiCqk3726VsOrBLjfn/DVijd6Htx0p9H28qHugjry4u8bRq9vid7Z1t72L7rKbyNVj8i9CfM4CjgLWayr4JfMv2jsDHaLF8bWJ9f2lOs+27qZZ3etkD28n2jrbf3mLadutwFnAr1Zeyx0DX4WXAV2m9Di8uce1m+5Km8oGuw2Wtv226k9vzimIobNdDwnBMCtdT7Tk9antR2dtbj+pL9AdJ61DtXf6j7c1tbw4cS69DbtvPAZ8Fdi8ndr8CfKZsDEhaSeVKpl5mAK9sE9vpVBtfzxHctcDBktYse3LvBn7XZlqAS4D/projvK6tqX5IainrazLVF6jHurx4UnZ8U/mTwNpt6vkz1cnhz1F9kaA6ETpC0usBJK0qafsWk/e1DicAJzX1X0u1h7+ypBHAG4EbW05ZORv4YjkJX9eA1mEH9LVN30Znt+cVwhDZroeE4ZgU/kR1hcYfe5U9Xk7+vgf4re2FTcMvpbrCZPXmimz/DfgacJLt24ETgAslzaD6kWjVdn0tsHOLK0Ao878EWL303wycQ/UjdgPwfdutmo56pn/S9pfLuyjqejOLN7fU8TWqddjj88CPVF0W23wC/efAu3tOyLWo52LgCKovIyXu9wFflnQb1V7/Hi2m+yXVj/tLlGax5nM2l1C1q98G/JaqXfjBdgtme67tb7Qb3saSrMNlqe02TXVSvpPb84qk29v1kJDHXHSBpG8AP7f9my7HsTpwDbBXryt5hjxJl1D9wN/d5ThGAhfY3qebcUQsK0kKXVB+SHaz3dUnwEoaA2xi++puxrEkJG0DjLR9bZfjeB3wnO1buxlHxLKSpBAREQ3D8ZxCRES0kaQQERENSQoREdGQpBBRg6R/lzRd0u3lUsTdak63saQf9zPOepI+3tc4EYMlJ5oj+lFuOjod2Nv2QlVP1FytPHeor+lWqXOpb3m0xuW2d1gW8UYsjRwpRPRvFPBwzw1gth+2/YCk10n6vap3EdwoaW1V7134kaSfA1eWJ2X2vNfiSEmXSvqVqncYnFrqPw3YqhyBfKU7ixhRGY4PxIsYqCuB/5D0/4DfUN2x+ofyeajtm8rjUXqef/R64NW2Hy1HAc12pXo42jPATZKuAE4GdijvaojoqhwpRPTD9lNUD4c7muoJtxdTPaNqnu2byjhPNDUVTWl6gmpvU2w/Uh4p8VOq5xJFDBk5UoiooTxm+mrgakl/onqoXLsTck/3VVU//RFdlSOFiH5I2qY8EqTHTlRPat24POaCcj6hzk7W2yRtUF7kdDDVE07bPnUzYrDlSCGify8HvilpParXN86iakr6YSl/GdX5hLfWqOs64FyqR39fYHsqgKTrywnpX9r+tw4sQ0QtuSQ1YpBIOhIYa/tfuh1LRDtpPoqIiIYcKUREREOOFCIioiFJISIiGpIUIiKiIUkhIiIakhQiIqLh/wP1tSq4n5okYAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "wmp = 189\n",
    "wnmp = 749\n",
    "nmp = 98\n",
    "nnmp = 396\n",
    "plt.bar(\"WARC (No MP)\", wnmp, color='red')\n",
    "plt.bar(\"Native (No MP)\", nnmp, color='orange')\n",
    "plt.bar(\"WARC\", wmp, color='green')\n",
    "plt.bar(\"Native\", nmp, color='blue')\n",
    "plt.xlabel('Script')\n",
    "plt.ylabel('Average time in Seconds')\n",
    "plt.title('Speed Tests (7 files with 16 threads)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*__Figure 2__: Speed Tests*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counter development\n",
    "\n",
    "Development of the counters did nor require as much troubleshooting as the onion finder did. The initial thought process was to pull the onions and websites from each CSV into another CSV. In that CSV the counts from each individual CSV were compiled; next the script opned that file and took any duplicate domain and its associated count and combined them. This removed all duplicates from the file but preserved the counts. The script then went through and sorted each domain by its count. The process was then repeated for the clear web sites. The method was not pretty, but got the job done. After further research and with help from Mr. King, the script was drastically minimized. This was done by forcing the script to compile all the CSVs into one dump file. The script will then use the pandas library to identify and remove duplicate domains and combine their counts. It then sorted the domains and saved the results to a another CSV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "The scripts ran on Aquamentus for approximatley 4 days. From the September Common Crawl Corpus, 40239 unique onion doains were discovered accross 6443 unique clear web sites. This was a 348% increase from the very first run with provided 5400 domains, and a 4% increase from the script Mr. King ran. This was likely due to my script checking the URL itself for onions as well as the extracted content. Out of the 40239 unique domains, 32966 were v2 domains and 7273 were v3 domains. TOR maintains a metric counting the amount of unique v2 domains on their network. The month of September had approximatley 75000 active domains. This means we found about 44% of the active domains that were active (See Figure 3 for a visualized comparison). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "usma = 32966\n",
    "tor = 75000\n",
    "plt.bar(\"USMA\", usma, color='g')\n",
    "plt.bar(\"TOR\", tor, color='orange')\n",
    "plt.xlabel('Group')\n",
    "plt.ylabel('# of v2 onions')\n",
    "plt.title('V2 Comparison')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*__Figure 3__: Visual comparison*\n",
    "\n",
    "From the CSV that provided the counts, the top ten onion domains were: \n",
    "\n",
    "1.\thydraruzxpnew4af.onion\n",
    "2.\tfacebookcorewwwi.onion\n",
    "3.\thydraruz4afxpnew.onion\n",
    "4.\t3g2upl4pq6kufc4m.onion\n",
    "5.\tprobiv7jg46vmbox.onion\n",
    "6.\twayawaytcl3k66fl.onion\n",
    "7.\tuj3wazyk5u4hnvtk.onion\n",
    "8.\thydra5etioavaz7p.onion\n",
    "9.\txmh57jrzrnw6insl.onion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dark Web Rudimentary Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing the top ten site involved navigating to the domain, interacting with the site, and querying google for extra information. This was done by utlizing a virutal machine (VM) with the Whonix OS. Whonix is a Linux distribution that focuses on anonymizing all of your web traffic and providing maximum security. This OS is safer when connecting to unknown onion sites due to its ability to 'sandbox' all applications, so should malware be installed it will be unable to determine the IP address of the host system.\n",
    "\n",
    "Out of the ten domains, three failed to connect after multiple attempts, one was classified as adware, and the remaining six were sites for illegal activities. the following figures are screenshots of what each domain returned along with a short description."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hydraruzxpnew4af.onion, hydra5etioavaz7p.onion, hydra6c2bnrd6phf.onion\n",
    "![](Final_Images/hydraetio.png)\n",
    "![](Final_Images/hydraref.png)\n",
    "\n",
    "*__Figure 4__: Hydra market*\n",
    "\n",
    "\n",
    "Hydra is a the top Russian marketplace on the darknet and very famous amount Russian speaking community. Hydra opened in 2015, providing a marketplace for illegal goods such as drugs and their ingredients, counterfeit documents and money, and hacking services. There is a reference at the bottom of each page, listing out the 7 active Hydra domains. There may be 7 as a remediation effort to keep their services up, should law enforcement seize the domain or should a hacker destroy it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### facebookcorewwwi.onion\n",
    "![](Final_Images/fb.png)\n",
    "\n",
    "*__Figure 5__: First failure*\n",
    "\n",
    "This is the dark web site for the Facebook. Has the same functionality as the clear web version, except all your traffic is encrypted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hydraruz4afxpnew.onion\n",
    "![](Final_Images/hydraruz4af.png)\n",
    "\n",
    "*__Figure 6__: First failure*\n",
    "\n",
    "This dark web address provides a connection error. This could be due to one of three things: it does not exist, does not run on port 80, exists but is currently offline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3g2upl4pq6kufc4m.onion\n",
    "![](Final_Images/3g2.png)\n",
    "\n",
    "*__Figure 7__: DuckDuckGo*\n",
    "\n",
    "This is the dark web site for the DuckDuckGo search engine. Has the same functionality as the clear web version, except all your traffic is encrypted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### probiv7jg46vmbox.onion\n",
    "![](Final_Images/probiv.png)\n",
    "\n",
    "*__Figure 8__: Probiv*\n",
    "\n",
    "Probiv is a Russian-language slang term best translated as “look-up”. This dark web domain focuses on the distribution of personally identifiable information (PII) for a price. Primary users are criminals and private investigators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### wayawaytcl3k66fl.onion\n",
    "![](Final_Images/wayaway.png)\n",
    "\n",
    "*__Figure 9__: Second failure*\n",
    "\n",
    "This dark web address provides a connection error. This could be due to one of three things: it does not exist, does not run on port 80, exists but is currently offline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### uj3wazyk5u4hnvtk.onion\n",
    "![](Final_Images/uj3.png)\n",
    "\n",
    "*__Figure 10__: Third failure*\n",
    "\n",
    "This dark web address provides a connection error. This could be due to one of three things: it does not exist, does not run on port 80, exists but is currently offline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xmh57jrzrnw6insl.onion\n",
    "![](Final_Images/xmh.png)\n",
    "\n",
    "*__Figure 11__: TORCH*\n",
    "\n",
    "Torch or TorSearch is at search engine for the dark web. They claim to be the best, oldest, and longest running search engine for the dark web. This search engine is only available at the dark web address above and via the TOR browser're also the oldest and longest running search engine on Tor. This site is also classified as adware."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acknlowedgements\n",
    "\n",
    "* Mr. Kyle King (NSA)\n",
    "* MAJ Daniel Hawthorne (U.S. Army)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Not sure how/if these are necessary. This was an attempt at a timeline of code development. May just remove it and link to the github."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python libraries that were initially used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re # Regular expression library\n",
    "import warc # warc3-wet. To read common crawl files.\n",
    "import csv # Output and input format\n",
    "from glob import glob # To find all files in specified directory\n",
    "from multiprocessing import Pool, cpu_count # To utilize multiple processors to speed up the script\n",
    "from subprocess import Popen, PIPE # Make the script universal\n",
    "from sys import platform # Determine system\n",
    "from os.path import splitext # Used in tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Regex compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regex for onions \n",
    "# onion_regex = r'([a-zA-Z2-7]{16}|[a-zA-Z2-7]{56})\\.onion?(?:\\/([^/ \\\\\\s]*))?'\n",
    "onion_regex = r'(?:[a-zA-Z2-7]{16}|[a-zA-Z2-7]{56})\\.onion'\n",
    "onion = re.compile(onion_regex, re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determine number of processors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine OS and number of processes to use\n",
    "def os_processes():\n",
    "    MAX_PROCESSES = 0\n",
    "    if platform == \"linux\" or platform == \"linux2\":\n",
    "        # linux\n",
    "        bashCommand = \"nproc\"\n",
    "        process = Popen(bashCommand.split(), stdout=PIPE)\n",
    "        output, error = process.communicate()\n",
    "        MAX_PROCESSES = int(output.decode().strip())\n",
    "    elif platform == \"darwin\":\n",
    "        # OS X\n",
    "        bashCommand = \"nproc\"\n",
    "        process = Popen(bashCommand.split(), stdout=PIPE)\n",
    "        output, error = process.communicate()\n",
    "        MAX_PROCESSES = int(output.decode().strip())\n",
    "    elif platform == \"win32\":\n",
    "        # Windows\n",
    "        MAX_PROCESSES = cpu_count()\n",
    "    return MAX_PROCESSES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt 1 (initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find Onions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find onions in data\n",
    "def find_onions(filename):\n",
    "    global onion\n",
    "    with warc.open(filename) as f:\n",
    "        with open(\"{}.csv\".format(filename.strip(\".warc.wet.gz\")), 'w', newline='') as output:\n",
    "            writer = csv.writer(output)\n",
    "            writer.writerow([\"Site\", \"Onion\"])\n",
    "            for record in f:\n",
    "                url = str(record.header.get('WARC-Target-URI', None))\n",
    "                data = str(record.payload.read())\n",
    "                url_match = re.search(onion, url)\n",
    "                payload_match = re.search(onion, data)\n",
    "                if url_match:\n",
    "                    onions = list(url_match)\n",
    "                    for o in onions:\n",
    "                        writer.writerow([url, o])\n",
    "                if payload_match:\n",
    "                    onions = list(payload_match)\n",
    "                    for o in onions:\n",
    "                        writer.writerow([url, o])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findall(pattern, string):\n",
    "    while True:\n",
    "        match = re.search(pattern, string)\n",
    "        if not match:\n",
    "            break\n",
    "        yield match.group(0)\n",
    "        string = string[match.end():]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Updated Find Onions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find onions in data\n",
    "def find_onions(filename):\n",
    "    global onion\n",
    "    with warc.open(filename) as f:\n",
    "        with open(\"{}.csv\".format(filename.strip(\".warc.wet.gz\")), 'w', newline='') as output:\n",
    "            writer = csv.writer(output)\n",
    "            writer.writerow([\"Site\", \"Onion\"])\n",
    "            for record in f:\n",
    "                url = str(record.header.get('WARC-Target-URI', None))\n",
    "                data = str(record.payload.read())\n",
    "                url_match = findall(onion, url)\n",
    "                payload_match = findall(onion, data)\n",
    "                if url_match:\n",
    "                    onions = list(url_match)\n",
    "                    for o in onions:\n",
    "                        writer.writerow([url, o])\n",
    "                if payload_match:\n",
    "                    onions = list(payload_match)\n",
    "                    for o in onions:\n",
    "                        writer.writerow([url, o])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt 3 (current)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Updated libraries (warc removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re # Regular expression library\n",
    "import gzip # Read the warc files\n",
    "import csv # Output and input format\n",
    "from io import BufferedReader # Speed improvement\n",
    "from glob import glob # To find all files in specified directory\n",
    "from multiprocessing import Pool, cpu_count # To utilize multiple processors to speed up the script\n",
    "from subprocess import Popen, PIPE # Make the script universal\n",
    "from sys import platform # Determine system\n",
    "from os.path import splitext # Used in tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final find onions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find onions in data\n",
    "def find_onions(filename):\n",
    "    global onion\n",
    "    gz = gzip.open(filename, 'rb')\n",
    "    f = BufferedReader(gz)\n",
    "    clear = ''\n",
    "    with open(\"{}.csv\".format(filename.strip(\".warc.wet.gz\")), 'w', newline='') as output:\n",
    "        writer = csv.writer(output)\n",
    "        for line in f:\n",
    "            url = re.search(r'WARC-Target-URI: (.+)\\r\\n', line.decode('utf8'))\n",
    "            if url:\n",
    "                clear = url\n",
    "            domain = re.search(onion, line.decode('utf8'))\n",
    "            if domain:\n",
    "                writer.writerow([domain.group(0), clear.group(1)])\n",
    "    gz.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    files = glob(\"*.warc.wet.gz\")\n",
    "    completed = glob(\"*.csv\")\n",
    "    completed = [splitext(c)[0] for c in completed]\n",
    "    if completed:\n",
    "        files = [f for f in files if f.strip(\".warc.wet.gz\") not in completed]\n",
    "    if len(files) == 0:\n",
    "        print(\"All Common Crawl Files have been searched!\")\n",
    "    else:\n",
    "        processors = os_processes()\n",
    "        print(\"Searching for onions.........\")\n",
    "        pool = Pool(processors)\n",
    "        pool.map(find_onions, files)\n",
    "        pool.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final onion_finder.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re # Regular expression library\n",
    "import gzip # Read the warc files\n",
    "import csv # Output and input format\n",
    "from io import BufferedReader # Speed improvement\n",
    "from glob import glob # To find all files in specified directory\n",
    "from multiprocessing import Pool, cpu_count # To utilize multiple processors to speed up the script\n",
    "from subprocess import Popen, PIPE # Make the script universal\n",
    "from sys import platform # Determine system\n",
    "from os.path import splitext # Used in tracking\n",
    "\n",
    "# Regex for onions \n",
    "# onion_regex = r'(?:https?\\:\\/\\/)?[a-zA-Z2-7]{16}\\.onion?(?:\\/([^/]*))?'\n",
    "onion_regex = r'(?:[a-zA-Z2-7]{16}|[a-zA-Z2-7]{56})\\.onion'\n",
    "onion = re.compile(onion_regex, re.IGNORECASE)\n",
    "\n",
    "# Determine OS and number of processes to use\n",
    "def os_processes():\n",
    "    MAX_PROCESSES = 0\n",
    "    if platform == \"linux\" or platform == \"linux2\":\n",
    "        # linux\n",
    "        bashCommand = \"nproc\"\n",
    "        process = Popen(bashCommand.split(), stdout=PIPE)\n",
    "        output, error = process.communicate()\n",
    "        MAX_PROCESSES = int(output.decode().strip())\n",
    "    elif platform == \"darwin\":\n",
    "        # OS X\n",
    "        bashCommand = \"nproc\"\n",
    "        process = Popen(bashCommand.split(), stdout=PIPE)\n",
    "        output, error = process.communicate()\n",
    "        MAX_PROCESSES = int(output.decode().strip())\n",
    "    elif platform == \"win32\":\n",
    "        # Windows\n",
    "        MAX_PROCESSES = cpu_count()\n",
    "    return MAX_PROCESSES\n",
    "\n",
    "# Find onions in data\n",
    "def find_onions(filename):\n",
    "    global onion\n",
    "    gz = gzip.open(filename, 'rb')\n",
    "    f = BufferedReader(gz)\n",
    "    clear = ''\n",
    "    with open(\"{}.csv\".format(filename.strip(\".warc.wet.gz\")), 'w', newline='') as output:\n",
    "        writer = csv.writer(output)\n",
    "        for line in f:\n",
    "            url = re.search(r'WARC-Target-URI: (.+)\\r\\n', line.decode('utf8'))\n",
    "            if url:\n",
    "                clear = url\n",
    "            domain = re.search(onion, line.decode('utf8'))\n",
    "            if domain:\n",
    "                writer.writerow([domain.group(0), clear.group(1)])\n",
    "    gz.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    files = glob(\"*.warc.wet.gz\")\n",
    "    completed = glob(\"*.csv\")\n",
    "    completed = [splitext(c)[0] for c in completed]\n",
    "    if completed:\n",
    "        files = [f for f in files if f.strip(\".warc.wet.gz\") not in completed]\n",
    "    if len(files) == 0:\n",
    "        print(\"All Common Crawl Files have been searched!\")\n",
    "    else:\n",
    "        processors = os_processes()\n",
    "        print(\"Searching for onions.........\")\n",
    "        pool = Pool(processors)\n",
    "        pool.map(find_onions, files)\n",
    "        pool.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt 1 (initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Onion Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv # Output and input format\n",
    "from urllib.parse import urlparse # Find domain\n",
    "from glob import glob # To find all files in specified directory\n",
    "from multiprocessing import Pool, cpu_count # To utilize multiple processors to speed up the script\n",
    "from subprocess import Popen, PIPE # Make the script universal\n",
    "from sys import platform # Determine system\n",
    "\n",
    "# Parse out domains onions were found on\n",
    "domain_regex = r'[a-zA-Z0-9][a-zA-Z0-9-]{1,}[a-zA-Z0-9](\\.[a-zA-Z]{2,})+'\n",
    "\n",
    "# Determine OS and number of processes to use\n",
    "def os_processes():\n",
    "    MAX_PROCESSES = 0\n",
    "    if platform == \"linux\" or platform == \"linux2\":\n",
    "        # linux\n",
    "        bashCommand = \"nproc\"\n",
    "        process = Popen(bashCommand.split(), stdout=PIPE)\n",
    "        output, error = process.communicate()\n",
    "        MAX_PROCESSES = int(output.decode().strip())\n",
    "    elif platform == \"darwin\":\n",
    "        # OS X\n",
    "        bashCommand = \"nproc\"\n",
    "        process = Popen(bashCommand.split(), stdout=PIPE)\n",
    "        output, error = process.communicate()\n",
    "        MAX_PROCESSES = int(output.decode().strip())\n",
    "    elif platform == \"win32\":\n",
    "        # Windows\n",
    "        MAX_PROCESSES = cpu_count()\n",
    "    return MAX_PROCESSES\n",
    "\n",
    "# Initial Counter\n",
    "def init_onions(filename):\n",
    "    file_onions = {}\n",
    "    with open(filename, 'r') as f:\n",
    "        reader = csv.reader(f, quotechar='\"', delimiter=',',\n",
    "                     quoting=csv.QUOTE_ALL, skipinitialspace=True)\n",
    "        next(reader)\n",
    "        with open(\"initial_counts.csv\", 'a+', newline='') as output:\n",
    "            writer = csv.writer(output)\n",
    "            for line in reader:\n",
    "                site = line[0]\n",
    "                onion_url = line[1]\n",
    "                onion = urlparse(\"http://\"+onion_url).netloc\n",
    "                file_onions.setdefault(onion, []).append(site)\n",
    "            for k,v in file_onions.items():\n",
    "                writer.writerow([k, len(v)])\n",
    "\n",
    "# Mid-Counter\n",
    "def mid_onions(filename):\n",
    "    init_mid_onions = []\n",
    "    domains = []\n",
    "    mid_onions = {}\n",
    "    with open(filename, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        with open(\"mid_counts.csv\", 'a+', newline='') as output:\n",
    "            writer = csv.writer(output)\n",
    "            for line in reader:\n",
    "                onion = line[0]\n",
    "                num = line[1]\n",
    "                if onion not in domains:\n",
    "                    domains.append(onion)\n",
    "                init_mid_onions.append([onion, num])\n",
    "            for d in domains:\n",
    "                count = 0\n",
    "                for p in init_mid_onions:\n",
    "                    if d == p[0]:\n",
    "                        count += int(p[1].rstrip())\n",
    "                    else:\n",
    "                        continue\n",
    "                mid_onions[d] = count\n",
    "            for k,v in mid_onions.items():\n",
    "                writer.writerow([k,v])\n",
    "\n",
    "# Final Counter\n",
    "def final_onions(filename):\n",
    "    sorted_onions = []\n",
    "    with open(filename, 'r') as f:\n",
    "        reader = csv.reader(f, delimiter=',')\n",
    "        sorted_onions = sorted(reader, key=lambda x: int(x[1]), reverse=True)\n",
    "        with open(\"final_counts.csv\", 'a+', newline='') as output:\n",
    "            writer = csv.writer(output)\n",
    "            # writer.writerow([\"Onion\", \"Frequency\"])\n",
    "            for x in sorted_onions:\n",
    "                writer.writerow([x[0], x[1]])\n",
    "\n",
    "\n",
    "# Create the search file\n",
    "def compile_onions():\n",
    "    sorted_onions = []\n",
    "    with open('final_counts.csv', 'r') as f:\n",
    "        with open(\"onions.csv\", 'a+') as output:\n",
    "            for line in f:\n",
    "                onion = line.split(',')[0]\n",
    "                output.write(\"{}\\n\".format(onion))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    files = glob(\"*.csv\")\n",
    "    processors = os_processes()\n",
    "    print(\"Initial Onion Count........\")\n",
    "    pool = Pool(processors)\n",
    "    pool.map(init_onions, files)\n",
    "    pool.close()\n",
    "    print(\"Mid Onion Count........\")\n",
    "    mid_onions('initial_counts.csv')\n",
    "    print(\"Final Onion Count........\")\n",
    "    final_onions('mid_counts.csv')\n",
    "    print(\"Compiling Onions........\")\n",
    "    compile_onions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Site Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv # Output and input format\n",
    "import tldextract # Find site domain\n",
    "from urllib.parse import urlparse # Find domain\n",
    "from glob import glob # To find all files in specified directory\n",
    "from multiprocessing import Pool, cpu_count # To utilize multiple processors to speed up the script\n",
    "from subprocess import Popen, PIPE # Make the script universal\n",
    "from sys import platform # Determine system\n",
    "from collections import defaultdict\n",
    "from os import remove\n",
    "\n",
    "# Determine OS and number of processes to use\n",
    "def os_processes():\n",
    "    MAX_PROCESSES = 0\n",
    "    if platform == \"linux\" or platform == \"linux2\":\n",
    "        # linux\n",
    "        bashCommand = \"nproc\"\n",
    "        process = Popen(bashCommand.split(), stdout=PIPE)\n",
    "        output, error = process.communicate()\n",
    "        MAX_PROCESSES = int(output.decode().strip())\n",
    "    elif platform == \"darwin\":\n",
    "        # OS X\n",
    "        bashCommand = \"nproc\"\n",
    "        process = Popen(bashCommand.split(), stdout=PIPE)\n",
    "        output, error = process.communicate()\n",
    "        MAX_PROCESSES = int(output.decode().strip())\n",
    "    elif platform == \"win32\":\n",
    "        # Windows\n",
    "        MAX_PROCESSES = cpu_count()\n",
    "    return MAX_PROCESSES\n",
    "\n",
    "# Initial Counter\n",
    "def init_sites(filename):\n",
    "    file_onions = {}\n",
    "    with open(filename, 'r') as f:\n",
    "        reader = csv.reader(f, quotechar='\"', delimiter=',',\n",
    "                     quoting=csv.QUOTE_ALL, skipinitialspace=True)\n",
    "        next(reader)\n",
    "        with open(\"initialized_site_data.csv\", 'a+', newline='') as output:\n",
    "            writer = csv.writer(output)\n",
    "            for line in reader:\n",
    "                url = line[0].lower()\n",
    "                extracted = tldextract.extract(url)\n",
    "                site = \"{}.{}\".format(extracted.domain, extracted.suffix)\n",
    "                onion_url = line[1].lower()\n",
    "                onion = urlparse(\"http://\"+onion_url).netloc\n",
    "                file_onions.setdefault(site, []).append(onion)\n",
    "            for k,v in file_onions.items():\n",
    "                writer.writerow([k, v,])\n",
    "    remove(\"initialized_site_data.csv\")\n",
    "\n",
    "# Mid-Counter\n",
    "def mid_sites(filename):\n",
    "    mid_sites = defaultdict(set)\n",
    "    with open(filename, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        with open(\"initial_site_counts.csv\", 'a+', newline='') as output:\n",
    "            writer = csv.writer(output)\n",
    "            for line in reader:\n",
    "                site = line[0]\n",
    "                onion = line[1]\n",
    "                mid_sites[site].add(onion)\n",
    "            for k,v in mid_sites.items():\n",
    "                writer.writerow([k,len(v)])\n",
    "\n",
    "# Final Counter\n",
    "def final_sites(filename):\n",
    "    sorted_sites = []\n",
    "    with open(filename, 'r') as f:\n",
    "        reader = csv.reader(f, delimiter=',')\n",
    "        sorted_sites = sorted(reader, key=lambda x: int(x[1]), reverse=True)\n",
    "        with open(\"site_counts.csv\", 'a+', newline='') as output:\n",
    "            writer = csv.writer(output)\n",
    "            for x in sorted_sites:\n",
    "                writer.writerow([x[0], x[1]])\n",
    "    remove(\"initial_site_counts.csv\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    files = glob(\"*.csv\")\n",
    "    processors = os_processes()\n",
    "    print(\"Initializing Sites........\")\n",
    "    pool = Pool(processors)\n",
    "    pool.map(init_sites, files)\n",
    "    pool.close()\n",
    "    print(\"Initial Site Count........\")\n",
    "    mid_sites('initialized_site_data.csv')\n",
    "    print(\"Final Site Count........\")\n",
    "    final_sites('initial_site_counts.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Onion Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv # Output and input format\n",
    "from urllib.parse import urlparse # Find domain\n",
    "from glob import glob # To find all files in specified directory\n",
    "from multiprocessing import Pool, cpu_count # To utilize multiple processors to speed up the script\n",
    "from subprocess import Popen, PIPE # Make the script universal\n",
    "from sys import platform # Determine system\n",
    "from os import remove # Clean up after counting\n",
    "\n",
    "# Determine OS and number of processes to use\n",
    "def os_processes():\n",
    "    MAX_PROCESSES = 0\n",
    "    if platform == \"linux\" or platform == \"linux2\":\n",
    "        # linux\n",
    "        bashCommand = \"nproc\"\n",
    "        process = Popen(bashCommand.split(), stdout=PIPE)\n",
    "        output, error = process.communicate()\n",
    "        MAX_PROCESSES = int(output.decode().strip())\n",
    "    elif platform == \"darwin\":\n",
    "        # OS X\n",
    "        bashCommand = \"nproc\"\n",
    "        process = Popen(bashCommand.split(), stdout=PIPE)\n",
    "        output, error = process.communicate()\n",
    "        MAX_PROCESSES = int(output.decode().strip())\n",
    "    elif platform == \"win32\":\n",
    "        # Windows\n",
    "        MAX_PROCESSES = cpu_count()\n",
    "    return MAX_PROCESSES\n",
    "\n",
    "# Initial Counter\n",
    "def init_onions(filename):\n",
    "    file_onions = {}\n",
    "    with open(filename, 'r') as f:\n",
    "        reader = csv.reader(f, quotechar='\"', delimiter=',',\n",
    "                     quoting=csv.QUOTE_ALL, skipinitialspace=True)\n",
    "        next(reader)\n",
    "        with open(\"initial_counts.csv\", 'a+', newline='') as output:\n",
    "            with open(\"dump.csv\", 'a+', newline='') as dump:\n",
    "                output_writer = csv.writer(output)\n",
    "                dump_writer = csv.writer(dump)\n",
    "                for line in reader:\n",
    "                    dump_writer.writerow([line[1], line[0]])\n",
    "                    site = line[0]\n",
    "                    onion_url = line[1]\n",
    "                    onion = urlparse(\"http://\"+onion_url).netloc\n",
    "                    file_onions.setdefault(onion, []).append(site)\n",
    "                for k,v in file_onions.items():\n",
    "                    output_writer.writerow([k, len(v)])\n",
    "\n",
    "# Mid-Counter\n",
    "def mid_onions(filename):\n",
    "    init_mid_onions = []\n",
    "    domains = []\n",
    "    mid_onions = {}\n",
    "    with open(filename, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        with open(\"mid_counts.csv\", 'a+', newline='') as output:\n",
    "            writer = csv.writer(output)\n",
    "            for line in reader:\n",
    "                onion = line[0]\n",
    "                num = line[1]\n",
    "                if onion not in domains:\n",
    "                    domains.append(onion)\n",
    "                init_mid_onions.append([onion, num])\n",
    "            for d in domains:\n",
    "                count = 0\n",
    "                for p in init_mid_onions:\n",
    "                    if d == p[0]:\n",
    "                        count += int(p[1].rstrip())\n",
    "                    else:\n",
    "                        continue\n",
    "                mid_onions[d] = count\n",
    "            for k,v in mid_onions.items():\n",
    "                writer.writerow([k,v])\n",
    "\n",
    "# Final Counter\n",
    "def final_onions(filename):\n",
    "    sorted_onions = []\n",
    "    with open(filename, 'r') as f:\n",
    "        reader = csv.reader(f, delimiter=',')\n",
    "        sorted_onions = sorted(reader, key=lambda x: int(x[1]), reverse=True)\n",
    "        with open(\"final_counts.csv\", 'a+', newline='') as output:\n",
    "            writer = csv.writer(output)\n",
    "            for x in sorted_onions:\n",
    "                writer.writerow([x[0], x[1]])\n",
    "\n",
    "\n",
    "# Create the search file\n",
    "def compile_onions():\n",
    "    sorted_onions = []\n",
    "    with open('final_counts.csv', 'r') as f:\n",
    "        with open(\"onions.csv\", 'a+') as output:\n",
    "            for line in f:\n",
    "                onion = line.split(',')[0]\n",
    "                output.write(\"{}\\n\".format(onion))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    files = glob(\"*.csv\")\n",
    "    processors = os_processes()\n",
    "    print(\"Initial Onion Count........\")\n",
    "    pool = Pool(processors)\n",
    "    pool.map(init_onions, files)\n",
    "    pool.close()\n",
    "    print(\"Mid Onion Count........\")\n",
    "    mid_onions('initial_counts.csv')\n",
    "    remove('initial_counts.csv')\n",
    "    print(\"Final Onion Count........\")\n",
    "    final_onions('mid_counts.csv')\n",
    "    remove('mid_counts.csv')\n",
    "    print(\"Compiling Onions........\")\n",
    "    compile_onions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Site Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Credit to Mr. Kyle King (NSA)\n",
    "\n",
    "import pandas as pd\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "df = pd.read_csv(\"dump.csv\")\n",
    "\n",
    "df[\"clearweb domain\"] = df[\"url\"].apply(lambda d: urlparse(d).netloc)\n",
    "\n",
    "pairs = df.drop('url', 1).groupby([\"onion\",\"clearweb domain\"]).size()\n",
    "\n",
    "domain_counts = pairs.groupby('clearweb domain').count().sort_values(ascending=False)\n",
    "\n",
    "domain_counts.reset_index().rename(columns={0:\"unique_site\"}).to_csv(\"site_counts.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt 3 (current) (Both in one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Credit to Mr. Kyle King (NSA)\n",
    "\n",
    "import pandas as pd\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "df = pd.read_csv(\"dump.csv\")\n",
    "\n",
    "# add a domain column\n",
    "df[\"clearweb domain\"] = df[\"url\"].apply(lambda d: urlparse(d).netloc)\n",
    "\n",
    "# # create a dataframe of unique domain/onion pairs\n",
    "pairs = df.drop('url', 1).groupby([\"onion\",\"clearweb domain\"]).size()\n",
    "\n",
    "# # unique onions on each domain\n",
    "onion_counts = pairs.groupby('onion').count().sort_values(ascending=False)\n",
    "domain_counts = pairs.groupby('clearweb domain').count().sort_values(ascending=False)\n",
    "\n",
    "# # write the results\n",
    "domain_counts.reset_index().rename(columns={0:\"unique_site\"}).to_csv(\"site_counts.csv\")\n",
    "onion_counts.reset_index().rename(columns={0:\"unique_onions\"}).to_csv(\"onion_counts.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
